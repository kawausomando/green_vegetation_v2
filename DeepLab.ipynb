{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules (Just run it once the first time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Python 3.8\n",
    "# ! pip3 install matplotlib\n",
    "# ! pip3 install numpy\n",
    "# ! pip3 install tensorflow\n",
    "# ! pip3 install pandas\n",
    "# ! pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 13:07:09.124045: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# @title Imports\n",
    "\n",
    "import os\n",
    "from io import BytesIO\n",
    "import tarfile\n",
    "import tempfile\n",
    "from six.moves import urllib\n",
    "\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model  (Just run it once the first time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Helper methods\n",
    "\n",
    "class DeepLabModel(object):\n",
    "  \"\"\"Class to load deeplab model and run inference.\"\"\"\n",
    "\n",
    "  INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
    "  OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
    "  INPUT_SIZE = 513\n",
    "  FROZEN_GRAPH_NAME = 'frozen_inference_graph'\n",
    "\n",
    "  def __init__(self, tarball_path):\n",
    "    \"\"\"Creates and loads pretrained deeplab model.\"\"\"\n",
    "    self.graph = tf.Graph()\n",
    "\n",
    "    graph_def = None\n",
    "    # Extract frozen graph from tar archive.\n",
    "    tar_file = tarfile.open(tarball_path)\n",
    "    for tar_info in tar_file.getmembers():\n",
    "      if self.FROZEN_GRAPH_NAME in os.path.basename(tar_info.name):\n",
    "        file_handle = tar_file.extractfile(tar_info)\n",
    "        graph_def = tf.compat.v1.GraphDef.FromString(file_handle.read())\n",
    "        break\n",
    "\n",
    "    tar_file.close()\n",
    "\n",
    "    if graph_def is None:\n",
    "      raise RuntimeError('Cannot find inference graph in tar archive.')\n",
    "\n",
    "    with self.graph.as_default():\n",
    "      tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    self.sess = tf.compat.v1.Session(graph=self.graph)\n",
    "\n",
    "  def run(self, image):\n",
    "    \"\"\"Runs inference on a single image.\n",
    "\n",
    "    Args:\n",
    "      image: A PIL.Image object, raw input image.\n",
    "\n",
    "    Returns:\n",
    "      resized_image: RGB image resized from original input image.\n",
    "      seg_map: Segmentation map of `resized_image`.\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "    resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n",
    "    target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
    "    resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
    "    batch_seg_map = self.sess.run(\n",
    "        self.OUTPUT_TENSOR_NAME,\n",
    "        feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\n",
    "    seg_map = batch_seg_map[0]\n",
    "    return resized_image, seg_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cityscape labels\n",
    "LABEL_NAMES = np.asarray([\n",
    "    'road','sidewalk','building',\n",
    "    'wall','fence','pole','traffic light','traffic sign',\n",
    "    'vegetation','terrain','sky','person','rider','car',\n",
    "    'truck','bus','train','motorcycle','bicycle','unlabeled',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_LABEL_MAP = np.arange(len(LABEL_NAMES)).reshape(len(LABEL_NAMES), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_COLOR_MAP = np.array([\n",
    "       [[  0,   0,   0]], # 'road'\n",
    "       [[128,   0,   0]], # 'sidewalk'\n",
    "       [[ 192, 192,   192]], # 'building'\n",
    "       [[128, 128,   0]], # 'wall'\n",
    "       [[  0,   0, 128]], # 'fence'\n",
    "       [[128,   0, 128]], # 'pole'\n",
    "       [[  0, 128, 128]], # 'traffic light'\n",
    "       [[128, 128, 128]], # 'traffic sign'\n",
    "       [[ 0,   192,   0]], # 'vegetation'\n",
    "       [[192,   0,   0]], # 'terrain'\n",
    "       [[ 64, 224,   208]], # 'sky'\n",
    "       [[192, 128,   0]], # 'person'\n",
    "       [[ 64,   0, 128]], # 'rider'\n",
    "       [[192,   0, 128]], # 'car'\n",
    "       [[ 64, 128, 128]], # 'truck'\n",
    "       [[192, 128, 128]], # 'bus'\n",
    "       [[  0,  64,   0]], # 'train'\n",
    "       [[255,  0,   255]], # 'motorcycle'\n",
    "       [[  64, 0,   0]], # 'bicycle'\n",
    "       [[128, 192,   0]] # 'unlabeled'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions  (Just run it once the first time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pascal_label_colormap():\n",
    "  \"\"\"Creates a label colormap used in PASCAL VOC segmentation benchmark.\n",
    "\n",
    "  Returns:\n",
    "    A Colormap for visualizing segmentation results.\n",
    "  \"\"\"\n",
    "  colormap = np.zeros((256, 3), dtype=int)\n",
    "  colormap = override_pascal_label_color_map(colormap)\n",
    "  ind = np.arange(256, dtype=int)\n",
    "\n",
    "  for shift in reversed(range(8)):\n",
    "    for channel in range(3):\n",
    "      colormap[:, channel] |= ((ind >> channel) & 1) << shift\n",
    "    ind >>= 3\n",
    "\n",
    "  return colormap\n",
    "\n",
    "def override_pascal_label_color_map(original):\n",
    "    \"\"\"Override default color map by custom color map edited by FULL_COLOR_MAP\n",
    "    Retruns:\n",
    "      Customed Colormap\n",
    "    \"\"\"\n",
    "    custommap = np.copy(original)\n",
    "    for index, color in enumerate(FULL_COLOR_MAP):\n",
    "        custommap[index] = color\n",
    "    \n",
    "    return custommap\n",
    "\n",
    "\n",
    "def label_to_color_image(label):\n",
    "  \"\"\"Adds color defined by the dataset colormap to the label.\n",
    "\n",
    "  Args:\n",
    "    label: A 2D array with integer type, storing the segmentation label.\n",
    "\n",
    "  Returns:\n",
    "    result: A 2D array with floating type. The element of the array\n",
    "      is the color indexed by the corresponding element in the input label\n",
    "      to the PASCAL color map.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If label is not of rank 2 or its value is larger than color\n",
    "      map maximum entry.\n",
    "  \"\"\"\n",
    "  if label.ndim != 2:\n",
    "    raise ValueError('Expect 2-D input label')\n",
    "\n",
    "  colormap = create_pascal_label_colormap()\n",
    "\n",
    "  if np.max(label) >= len(colormap):\n",
    "    raise ValueError('label value too large.')\n",
    "\n",
    "  return colormap[label]\n",
    "\n",
    "\n",
    "def vis_segmentation(image, seg_map):\n",
    "  \"\"\"Visualizes input image, segmentation map and overlay view.\"\"\"\n",
    "  plt.figure(figsize=(15, 5))\n",
    "  grid_spec = gridspec.GridSpec(1, 4, width_ratios=[6, 6, 6, 1])\n",
    "\n",
    "  plt.subplot(grid_spec[0])\n",
    "  plt.imshow(image)\n",
    "  plt.axis('off')\n",
    "  plt.title('input image')\n",
    "\n",
    "  plt.subplot(grid_spec[1])\n",
    "  seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
    "  plt.imshow(seg_image)\n",
    "  plt.axis('off')\n",
    "  plt.title('segmentation map')\n",
    "\n",
    "  plt.subplot(grid_spec[2])\n",
    "  plt.imshow(image)\n",
    "  plt.imshow(seg_image, alpha=0.7)\n",
    "  plt.axis('off')\n",
    "  plt.title('segmentation overlay')\n",
    "\n",
    "  unique_labels = np.unique(seg_map)\n",
    "  ax = plt.subplot(grid_spec[3])\n",
    "  plt.imshow(\n",
    "      FULL_COLOR_MAP[unique_labels].astype(np.uint8), interpolation='nearest')\n",
    "  ax.yaxis.tick_right()\n",
    "  plt.yticks(range(len(unique_labels)), LABEL_NAMES[unique_labels])\n",
    "  plt.xticks([], [])\n",
    "  ax.tick_params(width=0.0)\n",
    "  plt.grid('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mapping_single_file(path, file):\n",
    "    original_im = cv2.imread(path + file)\n",
    "    pilImg = Image.fromarray(np.uint8(original_im))\n",
    "    resized_im, seg_map = MODEL.run(pilImg)\n",
    "    return resized_im, seg_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vegetation(seg_map):\n",
    "    flaten_segmap = seg_map.flat\n",
    "    a = np.array(flaten_segmap)\n",
    "    # vegetationの割合\n",
    "    return (len(np.where(a==FULL_LABEL_MAP[8])[0]) / seg_map.size) *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download trained model  (Just run it once the first time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading model, this might take a while...\n",
      "download completed! loading DeepLab model...\n",
      "model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 13:10:17.060591: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#@title Select and download models {display-mode: \"form\"}\n",
    "\n",
    "# MODEL_NAME = 'mobilenetv2_coco_cityscapes_train' # 23MB\n",
    "MODEL_NAME = 'deeplabv3_cityscapes_train' # 439MB\n",
    "# MODEL_NAME = 'deeplab_cityscapes_xception71_trainfine' # 445MB\n",
    "# MODEL_NAME = 'deeplab_cityscapes_xception71_trainvalfine' # 446MB\n",
    "\n",
    "_DOWNLOAD_URL_PREFIX = 'http://download.tensorflow.org/models/'\n",
    "_MODEL_URLS = {\n",
    "    'mobilenetv2_coco_cityscapes_train':\n",
    "        'deeplabv3_mnv2_cityscapes_train_2018_02_05.tar.gz',\n",
    "    'deeplabv3_cityscapes_train':\n",
    "        'deeplabv3_cityscapes_train_2018_02_06.tar.gz',\n",
    "    'deeplab_cityscapes_xception71_trainfine':\n",
    "        'deeplab_cityscapes_xception71_trainfine_2018_09_08.tar.gz',\n",
    "    'deeplab_cityscapes_xception71_trainvalfine':\n",
    "        'deeplab_cityscapes_xception71_trainvalfine_2018_09_08.tar.gz'\n",
    "}\n",
    "_TARBALL_NAME = 'deeplab_model.tar.gz'\n",
    "\n",
    "model_dir = tempfile.mkdtemp()\n",
    "tf.io.gfile.makedirs(model_dir)\n",
    "\n",
    "download_path = os.path.join(model_dir, _TARBALL_NAME)\n",
    "print('downloading model, this might take a while...')\n",
    "urllib.request.urlretrieve(_DOWNLOAD_URL_PREFIX + _MODEL_URLS[MODEL_NAME],\n",
    "                   download_path)\n",
    "print('download completed! loading DeepLab model...')\n",
    "\n",
    "MODEL = DeepLabModel(download_path)\n",
    "print('model loaded successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mapping single file\n",
    "\n",
    "edit variable \"file\" and execute.\n",
    "\n",
    "if you don't need to show segmentaion info, comment out 'vis_segmentaion'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6f/6rhzl91s0lz8r397dzgrj2280000gn/T/ipykernel_56982/3246313260.py:47: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
      "2022-12-11 13:10:21.280357: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "file = '34584.jpg'\n",
    "resized_im, seg_map = mapping_single_file(path, file)\n",
    "seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
    "vis_segmentation(resized_im, seg_map)\n",
    "print(f'vegetation(%):{calc_vegetation(seg_map)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mapping multiple file\n",
    "\n",
    "execute mapping files under the 'path' variable (check the Setting sction)\n",
    "\n",
    "if you don't need to show segmentaion info, comment out 'vis_segmentaion'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mapping all file\n",
    "file_list = os.listdir(path)\n",
    "for _file in file_list:\n",
    "    print(f'filename: {_file}')\n",
    "    resized_im, seg_map = mapping_single_file(path, _file)\n",
    "    seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
    "    # vis_segmentation(resized_im, seg_map)\n",
    "    print(f'vegetation(%):{calc_vegetation(seg_map)} ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
